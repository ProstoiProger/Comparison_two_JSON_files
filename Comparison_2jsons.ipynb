{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a72aaa-2940-49c5-b056-85200b3c772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для того, чтобы pymorphy запускался на версиях Python 3.10+\n",
    "# В качестве альтернативы можно снести Python на версию раньше 3.10\n",
    "import inspect\n",
    "from collections import namedtuple\n",
    "\n",
    "if not hasattr(inspect, \"getargspec\"):\n",
    "    FullArgSpec = inspect.getfullargspec      \n",
    "    ArgSpec = namedtuple('ArgSpec',\n",
    "                         'args varargs keywords defaults')\n",
    "\n",
    "    def getargspec(func):\n",
    "        spec = FullArgSpec(func)\n",
    "        return ArgSpec(spec.args, spec.varargs,\n",
    "                       spec.varkw,  spec.defaults)\n",
    "\n",
    "    inspect.getargspec = getargspec           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12787fe-1939-476e-8545-b250f2c50400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import re\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d019c2-3fb3-4b1d-a289-7bd9fefb4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\", quiet = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bcbfc4-8e7c-4d16-b597-2ee15b497db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a98fbe-6bb8-4fac-80b9-93ec6d9af4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef400c87-f6e8-4b01-84d3-86ce370e25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_keys = [\"Наименование продукта\", \"Описание контракта\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b8986d-a53a-4a9f-98db-8792f554748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_json(obj: Dict):\n",
    "    trimmed = {}\n",
    "    for k, v in obj.items():\n",
    "        trimmed[k] = v\n",
    "        if k == 'Фамилии':\n",
    "            break\n",
    "    return trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e82575-86d5-4665-b2dd-e4a516d9042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_arrays(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return sorted({json.dumps(x, sort_keys = True, ensure_ascii = False) for x in obj})\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: normalize_arrays(v) for k, v in obj.items()}\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03f11dba-e61d-4fed-9a40-0abe3889a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fp: Path) -> dict:\n",
    "    obj = json.load(open(fp, encoding=\"utf-8\"))\n",
    "    obj = crop_json(obj)          \n",
    "    obj = normalize_arrays(obj)   \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56f3d4b7-9cca-43aa-8ae7-2df473eb13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rest(j1, j2):\n",
    "    a = {k: v for k, v in j1.items() if k not in emb_keys}\n",
    "    b = {k: v for k, v in j2.items() if k not in emb_keys}\n",
    "    return json.dumps(a, sort_keys=True, ensure_ascii=False), \\\n",
    "           json.dumps(b, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb3e85a6-5871-4945-b6dd-333032253bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_TOKEN_RE = re.compile(r\"[A-Za-zА-Яа-яЁё0-9]{2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41f8bdef-5b2d-4c13-b2d0-98447a937e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(text: str, mode: str = \"stem\") -> List[str]:\n",
    "    tokens = _TOKEN_RE.findall(text.lower())\n",
    "    if mode == \"stem\":\n",
    "        return [stemmer.stem(t) for t in tokens]\n",
    "    elif mode == \"lemma\":\n",
    "        return [morph.parse(t)[0].normal_form for t in tokens]\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be 'stem' or 'lemma'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20f5e654-a60d-44d4-9519-a48c4b4600d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bow_similarity(js1, js2, mode=\"stem\"):\n",
    "    s1, s2 = split_rest(js1, js2)\n",
    "    tfidf = TfidfVectorizer(tokenizer=lambda s: tokens(s, mode),\n",
    "                            lowercase=False).fit_transform([s1, s2])\n",
    "    return float(cosine_similarity(tfidf[0], tfidf[1])[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e2fd3be-47eb-495e-9357-924d8b3e636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fuzzy(js1, js2):\n",
    "    s1, s2 = split_rest(js1, js2)\n",
    "    return fuzz.token_sort_ratio(s1, s2) / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dda8d9d-e49e-44c7-a5e2-f8acafd0d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lcs_len(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [0]*(n+1)\n",
    "    for i in range(1, m+1):\n",
    "        prev = 0\n",
    "        for j in range(1, n+1):\n",
    "            cur = dp[j]\n",
    "            dp[j] = prev+1 if a[i-1]==b[j-1] else max(dp[j], dp[j-1])\n",
    "            prev = cur\n",
    "    return dp[n]\n",
    "\n",
    "def compare_lcs(js1, js2):\n",
    "    s1, s2 = split_rest(js1, js2)\n",
    "    return compare_lcs_len(s1, s2) / max(len(s1), len(s2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9c51439-a636-4104-9339-ab7115e623d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_bert_embedding(js1: Dict, js2: Dict):\n",
    "    s1 = \" \".join(str(js1.get(k, \"\")) for k in emb_keys)\n",
    "    s2 = \" \".join(str(js2.get(k, \"\")) for k in emb_keys)\n",
    "    v  = bert.encode([s1, s2], normalize_embeddings=True, convert_to_numpy=True)\n",
    "    return float(np.clip(np.dot(v[0], v[1]), -1.0, 1.0))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16385b12-e1e2-429f-913a-348874ee2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"embedding\" : lambda e,o: compare_bert_embedding(load_json(e), load_json(o)),\n",
    "    \"bow_stem\"  : lambda e,o: compare_bow_similarity(load_json(e), load_json(o), \"stem\"),\n",
    "    \"bow_lemma\" : lambda e,o: compare_bow_similarity(load_json(e), load_json(o), \"lemma\"),\n",
    "    \"fuzzy\"     : lambda e,o: compare_fuzzy(load_json(e), lo ad_json(o)),\n",
    "    \"lcs\"       : lambda e,o: compare_lcs(load_json(e), load_json(o)),\n",
    "}\n",
    "\n",
    "def compare_jsons(exp: Path, out: Path, method: str) -> float:\n",
    "    if method not in methods:\n",
    "        raise ValueError(f\"Unknown method {method}\")\n",
    "    return methods[method](exp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a39ee3d7-a922-41e4-a23b-b4084549ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding  = 1.0\n",
      "bow_stem   = 0.7989489812902651\n",
      "bow_lemma  = 0.7989489812902651\n",
      "fuzzy      = 0.7713310580204777\n",
      "lcs        = 0.7021617293835068\n"
     ]
    }
   ],
   "source": [
    "exp = Path(\"expected_4.json\")\n",
    "out = Path(\"output_4.json\")\n",
    "\n",
    "for method in methods:\n",
    "    print(method.ljust(10), \"=\", compare_jsons(exp, out, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736bf05-49ba-438a-8773-27460d9a19e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
